# @csrf_exempt
# def upload_complaint(request):
#     if request.method == 'POST':
#         lang = request.POST.get('language')
#         text = request.POST.get('text')

#         # Step 1: Detect language using Groq
#         language_check_prompt = f"What language is this text written in? Only give the language code like 'en', 'hi', 'bn'. Text: {text}"
#         detected_lang = query_groq(language_check_prompt)

#         if detected_lang.lower() != lang.lower():
#             return JsonResponse({'error': 'Entered language does not match selected language.'}, status=400)

#         # Step 2: Check cognizability and IPC
#         structured_prompt = """
# You are a JSON-only API. Always return a valid JSON object and nothing else.

# RULES:
# 1. No extra text, no markdown, no explanations — output only JSON.
# 2. First character must be '{', last character must be '}'.
# 3. All strings must be enclosed in double quotes.
# 4. If a field is truly impossible to fill, use "Unknown" for query-religion, or an empty array [] for lists.
# 5. Follow the schema exactly.

# FIELD RULES:
# - id: Always an integer starting from 1.
# - query-url: The most relevant, real URL (if any) related to the query’s legal context.
# - query-title: Short, descriptive title summarizing the query.
# - query-text: MUST be the **entire original query text exactly as provided in {{user_query}}, with no truncation, summarization, or omission**.
# - query-category: A specific legal category.
# - query-religion: Religion mentioned or implied; if none, use "Unknown".
# - responses: At least one helpful response with "responder" and "response-text".
# - citations: Short form, lowercase, number-first format
# - citations-id: IDs corresponding to the citations, as strings.

# TASK:
# Fill in this JSON using the schema above, based on the following query:

# {{user_query}}
# """

#         final_prompt = structured_prompt.replace("{{user_query}}", text or "")
#         structured_result = query_groq(final_prompt)

#         try:
#             parsed_json = json.loads(structured_result)
#         except json.JSONDecodeError:
#             return JsonResponse(
#                 {'error': 'LLM did not return valid JSON', 'raw': structured_result},
#                 status=500
#             )

#         return JsonResponse(parsed_json)


#     return JsonResponse({'error': 'Invalid method'}, status=405)


def query_google_gemma(prompt):
    headers = {
        "Content-Type": "application/json"
    }
    data = {
        "contents": [
            {
                "parts": [
                    {"text": prompt}
                ]
            }
        ]
    }
    url = f"https://generativelanguage.googleapis.com/v1beta/models/gemma-3-12b:generateContent?key={GOOGLE_STUDIO_API_KEY}"
    response = requests.post(url, headers=headers, json=data)
    if response.status_code == 200:
        return response.json()['candidates'][0]['content']['parts'][0]['text']
    else:
        return f"Google API error: {response.text}"

def query_huggingface_gemma(prompt):
    headers = {
        "Authorization": f"Bearer {HUGGING_FACE_API_KEY}",
        "Content-Type": "application/json"
    }
    
    data = {
        "inputs": prompt,
        "parameters": {
            "max_new_tokens": 512,
            "temperature": 0.7,
            "top_p": 0.9
        }
    }
    
    response = requests.post(
        "https://api-inference.huggingface.co/models/google/gemma-3-12b-it",
        headers=headers,
        json=data
    )
    
    if response.status_code == 200:
        result = response.json()
        if isinstance(result, list) and "generated_text" in result[0]:
            return result[0]["generated_text"]
        return result
    else:
        return f"Hugging Face API error: {response.text}"




        # for i, q in enumerate(query_texts, start=1):
        #     while True:
        #         prompt = structured_prompt_template.replace("{{user_query}}", q)
        #         raw_response = query_groq(prompt)

        #         if "groq api error" in raw_response.lower():
        #             print(f"Groq API error on query {i}, retrying in 5 seconds...")
        #             time.sleep(5)
        #             continue

        #         try:
        #             parsed_response = json.loads(raw_response)
        #         except json.JSONDecodeError:
        #             parsed_response = raw_response.strip()

        #         print(f"query {i}: {parsed_response}")

        #         results.append({
        #             "query_number": i,
        #             "query": q,
        #             "response": parsed_response
        #         })

        #         time.sleep(3)
        #         break

        # with open(output_path, "w", encoding="utf-8") as f:
        #     json.dump(results, f, ensure_ascii=False, indent=2)


        # def query_LSI_Gemma_model(prompt, retries=3, timeout=30):
#     HF_API_URL = "https://api-inference.huggingface.co/models/quirked/LSI_Gemma"
#     data = {"inputs": prompt}

#     for attempt in range(retries):
#         try:
#             response = requests.post(HF_API_URL, headers=HF_HEADERS, json=data, timeout=timeout)

#             if response.status_code == 200:
#                 result = response.json()
#                 # typical inference API returns [{"generated_text": "..."}]
#                 if isinstance(result, list) and "generated_text" in result[0]:
#                     return result[0]["generated_text"]
#                 else:
#                     return result
#             else:
#                 print("Error response:", response.text)
#                 return f"Hugging Face API error: {response.text}"

#         except (requests.exceptions.Timeout, requests.exceptions.ConnectionError) as e:
#             if attempt < retries - 1:
#                 time.sleep(5)
#             else:
#                 return f"Hugging Face API request failed after {retries} attempts: {str(e)}"


absl-py==2.2.1
accelerate==1.10.1
annotated-types==0.7.0
anyio==4.10.0
argon2-cffi==23.1.0
argon2-cffi-bindings==21.2.0
arrow==1.3.0
asgiref==3.9.1
asttokens==2.4.1
astunparse==1.6.3
async-lru==2.0.4
attrs==24.2.0
babel==2.16.0
beautifulsoup4==4.12.3
bleach==6.1.0
cachetools==5.5.2
certifi==2024.7.4
cffi==1.17.0
charset-normalizer==3.3.2
click==8.1.8
colorama==0.4.6
comm==0.2.2
contourpy==1.2.0
cycler==0.12.1
debugpy==1.8.5
decorator==5.1.1
defusedxml==0.7.1
distlib==0.3.9

executing==2.0.1
fastapi==0.115.12
fastjsonschema==2.20.0
filelock==3.17.0
flatbuffers==25.2.10
fonttools==4.48.1
fqdn==1.5.1
fsspec==2025.2.0
gast==0.6.0
google-ai-generativelanguage==0.6.15
google-api-core==2.25.1
google-api-python-client==2.179.0
google-auth==2.40.3
google-auth-httplib2==0.2.0
google-genai==1.31.0
google-generativeai==0.8.5
google-pasta==0.2.0
googleapis-common-protos==1.70.0
grpcio==1.74.0
grpcio-status==1.71.2

h11==0.14.0
h5py==3.13.0
httpcore==1.0.5
httplib2==0.22.0
httpx==0.28.1
huggingface-hub==0.34.4
idna==3.7
idx2numpy==1.2.3
ipykernel==6.29.5
ipython==8.26.0
ipywidgets==8.1.5
isoduration==20.11.0
jedi==0.19.1
Jinja2==3.1.4
joblib==1.4.2
json5==0.9.25
jsonpointer==3.0.0
jsonschema==4.23.0
jsonschema-specifications==2023.12.1
jupyter==1.0.0
jupyter-console==6.6.3
jupyter-events==0.10.0
jupyter-lsp==2.2.5
jupyter_client==8.6.2
jupyter_core==5.7.2
jupyter_server==2.14.2
jupyter_server_terminals==0.5.3
jupyterlab==4.2.4
jupyterlab_pygments==0.3.0
jupyterlab_server==2.27.3
jupyterlab_widgets==3.0.13
keras==3.9.1
kiwisolver==1.4.5
libclang==18.1.1
Markdown==3.7
markdown-it-py==3.0.0
MarkupSafe==2.1.5
matplotlib==3.8.2
matplotlib-inline==0.1.7
mdurl==0.1.2
mistune==3.0.2
ml_dtypes==0.5.1
mpmath==1.3.0
namex==0.0.8
nbclient==0.10.0
nbconvert==7.16.4
nbformat==5.10.4
neo4j==5.28.1
nest-asyncio==1.6.0
networkx==3.4.2
notebook==7.2.1
notebook_shim==0.2.4
numpy==1.26.4
opencv-python==4.9.0.80
opt_einsum==3.4.0
optree==0.14.1
overrides==7.7.0
packaging==24.1
pandas==2.2.2
pandocfilters==1.5.1
parso==0.8.4
peft==0.17.1

pipenv==2024.4.1
platformdirs==4.2.2
prometheus_client==0.20.0
prompt_toolkit==3.0.47
proto-plus==1.26.1
protobuf==5.29.4
psutil==6.0.0
psycopg2==2.9.10
pure_eval==0.2.3
pyasn1==0.6.1
pyasn1_modules==0.4.2
pycparser==2.22
pydantic==2.11.1
pydantic_core==2.33.0
Pygments==2.18.0
pyparsing==3.1.1
python-dateutil==2.9.0.post0

python-json-logger==2.0.7
pytz==2024.1
pywin32==306
pywinpty==2.0.13
PyYAML==6.0.2
pyzmq==26.2.0
qtconsole==5.5.2
QtPy==2.4.1
referencing==0.35.1
regex==2025.9.1

rfc3339-validator==0.1.4
rfc3986-validator==0.1.1
rich==13.9.4
rpds-py==0.20.0
rsa==4.9.1
safetensors==0.6.2
scikit-learn==1.5.1
scipy==1.14.1
seaborn==0.13.2
Send2Trash==1.8.3
setuptools==73.0.1
six==1.16.0
sniffio==1.3.1
soupsieve==2.6
sqlparse==0.5.3
stack-data==0.6.3
starlette==0.46.1
sympy==1.13.1
tenacity==9.1.2
tensorboard==2.19.0
tensorboard-data-server==0.7.2
tensorflow==2.19.1
tensorflow-hub==0.16.1
termcolor==2.5.0
terminado==0.18.1
tf_keras==2.19.0
threadpoolctl==3.5.0
tinycss2==1.3.0
tokenizers==0.22.0
torch==2.6.0
torchaudio==2.6.0
torchvision==0.21.0
tornado==6.4.1
tqdm==4.67.1
traitlets==5.14.3
transformers==4.56.1
types-python-dateutil==2.9.0.20240821
typing-inspection==0.4.0
typing_extensions==4.12.2
tzdata==2024.1
umpy==0.1.0
uri-template==1.3.0
uritemplate==4.2.0
urllib3==2.2.2
uvicorn==0.34.0
virtualenv==20.29.2
virtualenvwrapper-win==1.2.7
wcwidth==0.2.13
webcolors==24.8.0
webencodings==0.5.1
websocket-client==1.8.0
websockets==15.0.1
Werkzeug==3.1.3
wheel==0.45.1

widgetsnbextension==4.0.13
wrapt==1.17.2
